#!/usr/bin/env node

import yargs from 'yargs';
import { hideBin } from 'yargs/helpers';
import { retrieveMetadata } from './src/metadata-retriever.js';
import { cacheMetadata, clearCache } from './src/caching.js';
import { parseFile, parseCode } from './src/parser.js';
import { analyzeComplexity } from './src/complexity.js';
import { abstractFile, formatForLLM } from './src/abstraction.js';
import { formatAsSemanticContext, formatAsConstraintContext, formatAsImpactContext } from './src/llm-formatter.js';
import { SemanticGraph } from './src/semantic-graph.js';
import { ReferenceResolver } from './src/reference-resolver.js';
import { GraphSerializer } from './src/graph-serializer.js';
import { GraphAnalyzer } from './src/graph-analyzer.js';
import fse from 'fs-extra';
import yaml from 'js-yaml';

yargs(hideBin(process.argv))
  .command('ingest', 'Ingest metadata from Salesforce', async () => {
    try {
      console.log('Starting metadata ingestion...');

      const metadataTypes = [
        'ApexClass',
        'ApexTrigger',
        'CustomObject',
        'CustomLabels',
      ];

      await clearCache();
      await retrieveMetadata(metadataTypes);
      await cacheMetadata('./metadata');
      await fse.remove('./metadata');

      console.log('Metadata ingestion complete. Local cache created at .asfst-cache');
    } catch (error) {
      console.error('An error occurred during metadata ingestion:', error.message);
      process.exit(1);
    }
  })
  .command(
    'parse <file>',
    'Parse an Apex file and extract structured metadata',
    (yargs) => {
      return yargs
        .positional('file', {
          describe: 'Path to .cls or .trigger file',
          type: 'string',
        })
        .option('output', {
          alias: 'o',
          describe: 'Output format',
          choices: ['json', 'yaml'],
          default: 'json',
        })
        .option('pretty', {
          alias: 'p',
          describe: 'Pretty print output',
          type: 'boolean',
          default: true,
        })
        .option('complexity', {
          alias: 'c',
          describe: 'Include detailed complexity analysis',
          type: 'boolean',
          default: false,
        })
        .option('raw', {
          alias: 'r',
          describe: 'Include raw AST tree',
          type: 'boolean',
          default: false,
        });
    },
    async (argv) => {
      try {
        const result = await parseFile(argv.file, {
          includeRawTree: argv.raw,
        });

        // Add detailed complexity analysis if requested
        if (argv.complexity) {
          result.complexityAnalysis = analyzeComplexity(result);
        }

        // Output in requested format
        let output;
        if (argv.output === 'yaml') {
          output = yaml.dump(result, { 
            indent: 2, 
            lineWidth: 120,
            noRefs: true,
          });
        } else {
          output = argv.pretty 
            ? JSON.stringify(result, null, 2) 
            : JSON.stringify(result);
        }

        console.log(output);
      } catch (error) {
        console.error('Error parsing file:', error.message);
        process.exit(1);
      }
    }
  )
  .command(
    'analyze <file>',
    'Analyze complexity of an Apex file',
    (yargs) => {
      return yargs
        .positional('file', {
          describe: 'Path to .cls or .trigger file',
          type: 'string',
        })
        .option('output', {
          alias: 'o',
          describe: 'Output format',
          choices: ['json', 'yaml', 'text'],
          default: 'text',
        });
    },
    async (argv) => {
      try {
        const result = await parseFile(argv.file);
        const analysis = analyzeComplexity(result);

        if (argv.output === 'text') {
          // Human-readable output
          console.log(`\nComplexity Analysis: ${result.name}`);
          console.log('='.repeat(50));
          console.log(`Total Complexity: ${analysis.total} (${analysis.totalRating.level})`);
          console.log(`Average Method Complexity: ${analysis.average}`);
          console.log(`Number of Methods: ${analysis.methodCount}`);
          
          if (analysis.highComplexityMethods.length > 0) {
            console.log(`\nHigh Complexity Methods:`);
            for (const method of analysis.highComplexityMethods) {
              console.log(`  - ${method.name} (line ${method.line}): ${method.complexity} - ${method.rating.description}`);
            }
          }
          
          if (analysis.recommendations.length > 0) {
            console.log(`\nRecommendations:`);
            for (const rec of analysis.recommendations) {
              const icon = rec.severity === 'high' ? '!' : '-';
              console.log(`  ${icon} ${rec.message}`);
            }
          }
          
          console.log('');
        } else if (argv.output === 'yaml') {
          console.log(yaml.dump(analysis, { indent: 2, noRefs: true }));
        } else {
          console.log(JSON.stringify(analysis, null, 2));
        }
      } catch (error) {
        console.error('Error analyzing file:', error.message);
        process.exit(1);
      }
    }
  )
  .command(
    'context <file>',
    'Generate AI-friendly context abstraction for an Apex file',
    (yargs) => {
      return yargs
        .positional('file', {
          describe: 'Path to .cls or .trigger file',
          type: 'string',
        })
        .option('output', {
          alias: 'o',
          describe: 'Output format',
          choices: ['json', 'yaml', 'llm'],
          default: 'llm',
        })
        .option('method', {
          alias: 'm',
          describe: 'Focus on a specific method',
          type: 'string',
        })
        .option('depth', {
          alias: 'd',
          describe: 'Context depth for dependency tracing',
          type: 'number',
          default: 2,
        })
        .option('bodies', {
          alias: 'b',
          describe: 'Include condensed method bodies',
          type: 'boolean',
          default: false,
        })
        .option('max-lines', {
          describe: 'Max lines for method body preview',
          type: 'number',
          default: 10,
        })
        .option('no-schema', {
          describe: 'Skip schema resolution',
          type: 'boolean',
          default: false,
        });
    },
    async (argv) => {
      try {
        const abstraction = await abstractFile(argv.file, {
          targetMethod: argv.method,
          contextDepth: argv.depth,
          includeMethodBodies: argv.bodies,
          maxMethodBodyLines: argv['max-lines'],
          resolveSchema: !argv['no-schema'],
          includeValidationRules: !argv['no-schema'],
        });

        let output;
        if (argv.output === 'llm') {
          // Human/LLM readable format
          output = formatForLLM(abstraction);
          console.log(output);
          console.log(`\n# Estimated tokens: ~${abstraction.tokens}`);
        } else if (argv.output === 'yaml') {
          output = yaml.dump(abstraction, { 
            indent: 2, 
            lineWidth: 120,
            noRefs: true,
          });
          console.log(output);
        } else {
          output = JSON.stringify(abstraction, null, 2);
          console.log(output);
        }
      } catch (error) {
         console.error('Error generating context:', error.message);
         process.exit(1);
       }
     }
   )
   .command(
     'semantic <file>',
     'Generate semantic context (intent-focused) for code understanding',
     (yargs) => {
       return yargs
         .positional('file', {
           describe: 'Path to .cls or .trigger file',
           type: 'string',
         })
         .option('no-schema', {
           describe: 'Skip schema resolution',
           type: 'boolean',
           default: false,
         });
     },
     async (argv) => {
       try {
         const abstraction = await abstractFile(argv.file, {
           resolveSchema: !argv['no-schema'],
         });
         const output = formatAsSemanticContext(abstraction);
         console.log(output);
       } catch (error) {
         console.error('Error generating semantic context:', error.message);
         process.exit(1);
       }
     }
   )
   .command(
     'constraints <file>',
     'Generate constraint-focused context for validation and schema understanding',
     (yargs) => {
       return yargs
         .positional('file', {
           describe: 'Path to .cls or .trigger file',
           type: 'string',
         })
         .option('no-schema', {
           describe: 'Skip schema resolution',
           type: 'boolean',
           default: false,
         });
     },
     async (argv) => {
       try {
         const abstraction = await abstractFile(argv.file, {
           resolveSchema: !argv['no-schema'],
         });
         const output = formatAsConstraintContext(abstraction);
         console.log(output);
       } catch (error) {
         console.error('Error generating constraint context:', error.message);
         process.exit(1);
       }
     }
   )
   .command(
     'impact <file>',
     'Generate impact analysis (blast radius and risk assessment)',
     (yargs) => {
       return yargs
         .positional('file', {
           describe: 'Path to .cls or .trigger file',
           type: 'string',
         })
         .option('no-schema', {
           describe: 'Skip schema resolution',
           type: 'boolean',
           default: false,
         });
     },
     async (argv) => {
       try {
         const abstraction = await abstractFile(argv.file, {
           resolveSchema: !argv['no-schema'],
         });
         const output = formatAsImpactContext(abstraction);
         console.log(output);
       } catch (error) {
         console.error('Error generating impact analysis:', error.message);
         process.exit(1);
       }
     }
    )
    .command(
      'graph <file>',
      'Build and analyze semantic dependency graph (DAG)',
      (yargs) => {
        return yargs
          .positional('file', {
            describe: 'Path to .cls or .trigger file',
            type: 'string',
          })
          .option('format', {
            alias: 'f',
            describe: 'Output format',
            choices: ['json', 'yaml', 'compact'],
            default: 'json',
          })
          .option('include-context', {
            describe: 'Include context radius for first method',
            type: 'boolean',
            default: false,
          })
          .option('context-depth', {
            describe: 'Context depth (1-5)',
            type: 'number',
            default: 2,
          });
      },
      async (argv) => {
        try {
          const sourceCode = await fse.readFile(argv.file, 'utf-8');
          const parsed = await parseFile(argv.file);
          const graph = new SemanticGraph([parsed]);
          const sourceCodeMap = new Map([[parsed.file, sourceCode]]);
          new ReferenceResolver(graph, [parsed], sourceCodeMap);
          
          const serializer = new GraphSerializer(graph);
          let output;

          if (argv['include-context'] && graph.methodNodes.size > 0) {
            const methodId = graph.methodNodes.values().next().value;
            output = serializer.serializeContextRadius(methodId, argv['context-depth']);
          } else {
            output = serializer.serializeFullGraph();
          }

          if (argv.format === 'yaml') {
            console.log(yaml.dump(output, { lineWidth: -1 }));
          } else if (argv.format === 'compact') {
            if (graph.methodNodes.size > 0) {
              const methodId = graph.methodNodes.values().next().value;
              output = serializer.serializeCompact(methodId, argv['context-depth']);
            }
            console.log(JSON.stringify(output));
          } else {
            console.log(JSON.stringify(output, null, 2));
          }
        } catch (error) {
          console.error('Error building graph:', error.message);
          process.exit(1);
        }
      }
    )
    .command(
      'hotspots <file>',
      'Identify critical hotspots in code (most depended-on elements)',
      (yargs) => {
        return yargs
          .positional('file', {
            describe: 'Path to .cls or .trigger file',
            type: 'string',
          })
          .option('limit', {
            alias: 'l',
            describe: 'Number of hotspots to show',
            type: 'number',
            default: 10,
          })
          .option('format', {
            alias: 'f',
            describe: 'Output format',
            choices: ['json', 'yaml', 'table'],
            default: 'table',
          });
      },
      async (argv) => {
        try {
          const sourceCode = await fse.readFile(argv.file, 'utf-8');
          const parsed = await parseFile(argv.file);
          const graph = new SemanticGraph([parsed]);
          const sourceCodeMap = new Map([[parsed.file, sourceCode]]);
          new ReferenceResolver(graph, [parsed], sourceCodeMap);
          
          const analyzer = new GraphAnalyzer(graph);
          const hotspots = analyzer.findHotspots(argv.limit);

          if (argv.format === 'table') {
            console.log('\nðŸ“ Code Hotspots (Most Critical Elements)\n');
            console.log('Rank | Name                       | Type    | Criticality');
            console.log('-----|----------------------------|---------|-------------');
            hotspots.forEach((h, i) => {
              const name = h.name.substring(0, 26).padEnd(26);
              const type = h.type.padEnd(7);
              console.log(
                `${String(i + 1).padStart(4)} | ${name} | ${type} | ${h.criticalityScore.toString().padStart(3)}`
              );
            });
            console.log();
          } else if (argv.format === 'yaml') {
            console.log(yaml.dump(hotspots, { lineWidth: -1 }));
          } else {
            console.log(JSON.stringify(hotspots, null, 2));
          }
        } catch (error) {
          console.error('Error analyzing hotspots:', error.message);
          process.exit(1);
        }
      }
    )
    .command(
      'issues <file>',
      'Detect code issues (dead code, cycles, unused fields)',
      (yargs) => {
        return yargs
          .positional('file', {
            describe: 'Path to .cls or .trigger file',
            type: 'string',
          })
          .option('format', {
            alias: 'f',
            describe: 'Output format',
            choices: ['json', 'yaml', 'summary'],
            default: 'summary',
          });
      },
      async (argv) => {
        try {
          const sourceCode = await fse.readFile(argv.file, 'utf-8');
          const parsed = await parseFile(argv.file);
          const graph = new SemanticGraph([parsed]);
          const sourceCodeMap = new Map([[parsed.file, sourceCode]]);
          new ReferenceResolver(graph, [parsed], sourceCodeMap);
          
          const analyzer = new GraphAnalyzer(graph);
          const issues = analyzer.detectIssues();

          if (argv.format === 'summary') {
            console.log('\nðŸ” Code Quality Issues\n');
            console.log(`Dead Methods:    ${issues.deadMethods.length}`);
            if (issues.deadMethods.length > 0) {
              issues.deadMethods.slice(0, 5).forEach(m => {
                console.log(`  - ${m.method}`);
              });
            }
            console.log(`Unused Fields:   ${issues.unusedFields.length}`);
            if (issues.unusedFields.length > 0) {
              issues.unusedFields.slice(0, 5).forEach(f => {
                console.log(`  - ${f.field}`);
              });
            }
            console.log(`Cycles:          ${issues.cycles.length}`);
            console.log();
          } else if (argv.format === 'yaml') {
            console.log(yaml.dump(issues, { lineWidth: -1 }));
          } else {
            console.log(JSON.stringify(issues, null, 2));
          }
        } catch (error) {
          console.error('Error detecting issues:', error.message);
          process.exit(1);
        }
      }
    )
    .command(
      'complexity-report <file>',
      'Generate detailed complexity analysis report',
      (yargs) => {
        return yargs
          .positional('file', {
            describe: 'Path to .cls or .trigger file',
            type: 'string',
          })
          .option('format', {
            alias: 'f',
            describe: 'Output format',
            choices: ['json', 'yaml', 'summary'],
            default: 'summary',
          });
      },
      async (argv) => {
        try {
          const sourceCode = await fse.readFile(argv.file, 'utf-8');
          const parsed = await parseFile(argv.file);
          const graph = new SemanticGraph([parsed]);
          const sourceCodeMap = new Map([[parsed.file, sourceCode]]);
          new ReferenceResolver(graph, [parsed], sourceCodeMap);
          
          const analyzer = new GraphAnalyzer(graph);
          const report = analyzer.generateComplexityReport();

          if (argv.format === 'summary') {
            console.log('\nðŸ“Š Complexity Analysis Report\n');
            console.log(`Total Methods:    ${report.methodCount}`);
            console.log(`Average Complexity: ${report.avgComplexity}`);
            console.log(`Max Complexity:   ${report.maxComplexity}`);
            console.log(`\nMost Complex Methods:`);
            report.mostComplex.slice(0, 5).forEach((m, i) => {
              console.log(`  ${i + 1}. ${m.name} (complexity: ${m.complexity})`);
            });
            console.log();
          } else if (argv.format === 'yaml') {
            console.log(yaml.dump(report, { lineWidth: -1 }));
          } else {
            console.log(JSON.stringify(report, null, 2));
          }
        } catch (error) {
          console.error('Error generating complexity report:', error.message);
          process.exit(1);
        }
      }
    )
    .demandCommand(1)
   .help()
   .alias('help', 'h')
   .version()
   .alias('version', 'v')
   .parse();
